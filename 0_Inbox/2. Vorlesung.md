#### Definition 1.7 (Supremum).
Eine reelle Zahl s heißt **Supremum** einer Teilmenge M von R, dalls s eine obere Schranke von M ist und falls $s \le x$ für jede obere Schranke x von M $\implies$ sup(M)

Konvention: $sup(\emptyset) = -\infty, sup(M) = \infty,$ falls M nach oben unbeschränkt ist.
**Jede nicht leere nach oben beschränkte Teilmenge von R besitzt ein Supremum!**
Diese Eigenschaft von $R$ heißt auch **Vollständigkeit**.
Wichtig: Das gilt nicht für Teilmenge von $Q$, Supremum muss nicht in Q liegen da fur $x < y, \hspace{2mm} x,y \in R$ gibt es ein $z \in Q \text{ mit } x < z < y$.  

Analog definieren wir untere Schranke, Minimum und Infimum geschrieben $inf(M)$ .
Konvention: $inf(\emptyset) = \infty$ und $inf(M) = -\infty$, falls M nicht nach unten beschränkt ist.

### Rechenregeln für Suprema und Maxima
**Satz 1.8.** Seien $A,B \subseteq R$ mit $sup(A), sup(B) \in R$ (also nicht $+\infty$ ).
Dann gilt $sup(A + B) = sup(A) + sup(B)$.
Dabei ist $A + B = \{a + b : a \in A, b \in B\}$.
Falls $\lambda \ge 0$, so gilt $sup(\lambda \cdot A) = \lambda \cdot sup(A)$. Dabei ist $\lambda \cdot A = \{\lambda \cdot a : a \in A\}$. 
Sind $A,B \subseteq [0, \infty)$ so gilt $sup(A \cdot B) = sup(A) \cdot sup(B)$.
Falls $A \subseteq B$ so gilt $sup(A)\le sup(B)$.

*Beweis:* $$\begin{aligned}&A \subseteq B \text{ folgt dass } \forall x \in A,B \hspace{4mm}\exists y \in B \text{ und } y \notin A. \\ 
&\text{Falls y ist das Maximum von B dann folgt dass } sup(B) > sup(A). \\ &\text{Sonst werden A und B das gleiche Maximum haben und daraus folgt:} \\ &sup(A) = sup(B). \\ &\text{Deswegen: } sup(A) \le sup(B).
\end{aligned}$$
Wegen $$inf(A) = -sup(-A)$$
wobei $-A = \{-a: a \in A\}$, gelten dieselben Regeln auch für das Infimum, wobei statt(1.3) für $A \subseteq B$ gilt$$inf(A) \ge inf(B).$$
*Die Dreiecksungleichung*
Für $x \in R$ definieren wir: $|x| = max(\{-x, x\})$, d.h.  $$|x| = \left\{ \begin{array}{ll} x, & \text{if } x \geq 0 \\ -x, & \text{if } x < 0 \end{array} \right.$$
Für $x,y \in R$ gilt: $|x| \ge 0, |x| = 0 \iff x = 0$ 
$|x \cdot y| = |x| \cdot |y|.$ **Dreiecksungleichung:**$$|x + y| \le |x| + |y|.$$
In (1.6) gilt `=` genau dann wenn x und y dasselbe Vorzeichen haben.
Umgekehrte Dreiecksungleichung:$$|x - y| \ge ||x| - |y||.$$
**Bernoulli-Ungleichung**$$(1+x)^n \ge 1 + n \cdot x, \hspace{3mm} \forall n \in N, \forall x \ge -1.$$
*Beweis:* Übung (mit vollständiger Induktion) $\implies (Ipad)$.

**Ungleichung zwischen geometrischen und arithmetischem Mittel**
Seien $x,y \ge 0$. Dann gilt:$$\begin{equation}
    \sqrt{x \cdot y} \leq \frac{x + y}{2}
\end{equation}
$$
Links: geometrisches Mittel, rechts: arithmetisches Mittel
*Beweis.* $0 \le (x - y)^2 = x^2 - 2xy + y^2 = x^2 + 2xy + y^2 - 4xy = (x + y)^2 - 4xy$
Also: $4xy\ge(x+y)^2$ und damit $$xy\ge \Bigl( \frac{x + y}{2} \Bigl)^2$$
==Gleichheit gilt genau dann wenn x = y==.   

Der **Vektorraum** $R^n$ besteht aus Vektoren der Form $x = (x1, \ldots, x-n)$ mit $x_i \in R, 1 \le i \le n$. (==x ist jetz ein Vektor war eine Zahl vorher==).

Die **Länge eines Vektors** ist definiert als $$
||x|| = \sqrt{x_1^2 + \ldots + x_n^2} = \Biggl(\sum_{i = 1}^{n}x_i^2\Biggl)^{\frac{1}{2}} 
$$
Das **Skalarprodukt** zweier Vektoren $x,y \in R^n$ ist definiert als $\langle x,y \rangle = \sum_{i = 1}^n x_i \cdot y_i$. Dann gilt: $||x|| = \sqrt{\langle x, x\rangle}$. 
Es gilt $||x|| \ge 0$ mit Gleichheit $\iff x = (0,0, \ldots,0)$.

**Cauchy-Schwarz-Ungleichung**$$|\langle x, y\rangle| \le ||x|| \cdot ||y|| \hspace{3mm} \forall x,y \in R$$
Gleichheit $\iff \alpha, \beta \ge 0$ gibt, so dass nicht $\alpha = \beta = 0$ mit $\alpha \cdot x_k = \beta \cdot y_k, 1 \le k \le n$.  
*Beweis.* Wir wollen zeigen, dass $$\sum_{k = 1}^n x_k \cdot y_k \le s_x \cdot s_y,$$
wobei $s_x = \sqrt{\sum_{k=1}^n x_k^2}, s_y = \sqrt{\sum_{k=1}^n y_k^2}$. Falls einer der Vektoren der Nullvektor ist so ist das richtig: falls $x_1 = \ldots = x_n = 0$ oder $y_1 = \ldots = y_n = 0$ so ist $\langle x, y\rangle = ||x||\cdot||y||$ und $(\alpha, \beta) = (1,0)$ oder $(\alpha, \beta) = (0,1)$. Wir nehmen auch an, dass $s_x > 0, s_y > 0$. Wir versuchen $\sum_{k=1}^n x_k \cdot y_k$ nach oben abzuschätzen: wegen `(1.9)`  gilt $x_k \cdot y_k \le \frac{x_k^2 + y_k^2}{2}$. Wir summieren über k:$$\sum_{k=1}^n x_k \cdot y_k \le \frac{1}{2}(s_x^2 + s_y^2)$$
mit Gleichheit $\iff$ $x_k = y_k,\forall k$. Wegen `(1.9)` gilt auch $s_x \cdot s_y \le \frac {1}{2}(s_x^2 + s_y^2)$, deswegen ist `(1.11)` zu grob, es sei denn $s_x = s_y.$ Also: $\bar{x_k} = \frac{x_k}{s_k} \hspace{4mm} \bar{y_k}=\frac{y_k}{s_y}, 1\le k\le n$.
Dann gilt: $s_{\bar x} = s_{\bar y} = 1$  und `(1.11)` liefer $\sum_{k = 1}^n \bar{x_k} \cdot \bar{y_k} \le 1$. Also: $\sum_{k = 1}^n x_k \cdot y_K \le 1$ und Gleichheit gilt $\iff$ $\bar{x_k} = \bar{y_k}$, also $\alpha = s_y,\beta = s_x \hspace{2mm} \alpha,\beta \not=0$.  
 

 # Links: 


202410161424
[[2024-10-16]]